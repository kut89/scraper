{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import chromedriver_binary\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下の関数は文字の整形\n",
    "def translate(text):\n",
    "    comment_pattern = re.compile(r'//([^\\n]*)')\n",
    "    out = re.sub(comment_pattern, r'\\1', text)\n",
    "\n",
    "    out = re.sub(r'^\\s*|\\s*(?=\\s)|\\s*$', '', out)\n",
    "#下の3行は原文の改行区切りを残すため\n",
    "    out = re.sub(r'\\.\\n', r'#######################', out)\n",
    "    out = re.sub(r'[\\r\\n]', ' ', out)\n",
    "    out = re.sub(r'#######################', r'.\\n', out)\n",
    "    out = re.sub(r':\\s+', r':\\n', out)\n",
    "    out = re.sub(r'/', r'%', out)\n",
    "    out = ' '.join('\\n' + line if ' ' in line else line for line in out.splitlines())\n",
    "#     print(out)\n",
    "    \n",
    "# 以下でスクレイピング を行う\n",
    "    options = Options()\n",
    "    options.add_argument('--headress')\n",
    "    browser = webdriver.Chrome(chrome_options=options)\n",
    "    browser.implicitly_wait(3)\n",
    "    url_text = \"https://translate.google.co.jp/#en/ja/{0}\".format(out)\n",
    "    url = urllib.parse.quote_plus(url_text, \"/:?=&#\")\n",
    "    browser.get(url)\n",
    "    result = BeautifulSoup(browser.page_source, \"html.parser\").find(class_ = \"tlid-translation translation\").text\n",
    "#     print(result)\n",
    "    browser.quit()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kut/.pyenv/versions/anaconda3-4.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検索、推奨、およびオンライン広告は、最も重要な3つの情報提供アルゴリズムです。最初に最適な価値関数を見つけ、次に最適なポリシーを抽出するアルゴリズムは、Dyna、Qラーニング、SARSA、DQNなどの価値関数メソッドです[Mnih他2015]。代替アプローチは、ポリシーの空間を直接検索してMDP問題を解決するポリシー検索方法です。ポリシー検索メソッドの重要なクラスは、ポリシーグラディエント（PG）アルゴリズムのクラスです[Williams 1992;バクスターとバートレット2001;カカデ2001; Deisenroth and Rasmussen 2011]。これらの方法は、ポリシーを直接モデル化および最適化することを目的としています。ポリシーは通常、（ajs）に関してパラメーター化された関数でモデル化されます。報酬（目的）関数の値はこのポリシーに依存し、さまざまなアルゴリズムを適用して最適な報酬を最適化できます。 PGを使用してポリシー空間を検索し、同時に価値関数を推定する一連のアルゴリズムがあります。これらのメソッドの重要なクラスは、Actor-Critic（AC）とそのバリエーションです[Konda and Tsitsiklis 1999;ピーターズ等。 2005;ピーターズとシャール2008; Bhatnagar et al。 2007; Bhatnagar et al。 2009]。これらは2タイムスケールのアルゴリズムであり、評論家は線形近似アーキテクチャで時間差（TD）学習を使用し、評論家から提供された情報に基づいてアクターが近似勾配方向で更新されます。\n"
     ]
    }
   ],
   "source": [
    "# 下の部分にいれた文字列をGoogle翻訳に渡してスクレイピング\n",
    "\n",
    "english = \"\"\"\n",
    "Search, recommendation, and online advertising are the three most important information-providing\n",
    "The algorithms, which first find the optimal value\n",
    "functions and then extract optimal policies, are value function methods, such as Dyna,\n",
    "Q-learning, SARSA, and DQN [Mnih et al. 2015]. The alternative approaches are policy\n",
    "search methods which solve an MDP problem by directly searching in the space of\n",
    "policies. An important class of policy search methods is that of Policy Gradient (PG)\n",
    "algorithms [Williams 1992; Baxter and Bartlett 2001; Kakade 2001; Deisenroth and Rasmussen\n",
    "2011]. These methods target at modeling and optimizing the policy directly. The\n",
    "policy is usually modeled with a parameterized function with respect to \u0019\u0012(ajs). The\n",
    "value of the reward (objective) function depends on this policy and then various algorithms\n",
    "can be applied to optimize \u0012 for the best reward. There are a series of algorithms, which\n",
    "use the PG to search in the policy space, and at the same time estimate a value function.\n",
    "The important class of these methods are Actor-Critic (AC) and its variation [Konda and\n",
    "Tsitsiklis 1999; Peters et al. 2005; Peters and Schaal 2008; Bhatnagar et al. 2007; Bhatnagar\n",
    "et al. 2009]. These are two-time-scale algorithms where the critic uses Temporal-\n",
    "Difference (TD) learning with a linear approximation architecture and the actor is updated\n",
    "in an approximate gradient direction based on information provided by the critic.\n",
    "\"\"\"\n",
    "\n",
    "print(translate(english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
